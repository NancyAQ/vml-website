<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Human Pose Estimation &amp; Analysis on VML-BGU</title><link>https://nancyaq.github.io/vml-website/projects/pose-estimation/</link><description>Recent content in Human Pose Estimation &amp; Analysis on VML-BGU</description><generator>Hugo</generator><language>en</language><atom:link href="https://nancyaq.github.io/vml-website/projects/pose-estimation/index.xml" rel="self" type="application/rss+xml"/><item><title>Comprehensive Survey of 3D Human Pose Estimation</title><link>https://nancyaq.github.io/vml-website/projects/pose-estimation/survey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nancyaq.github.io/vml-website/projects/pose-estimation/survey/</guid><description>&lt;h3 id="overview"&gt;Overview&lt;/h3&gt;
&lt;p&gt;This project involves creating the most comprehensive survey to date on 3D Human Pose Estimation methods. We systematically categorize over 200 papers published in the last five years, creating a clear taxonomy of approaches, and providing quantitative comparisons of performance across standard benchmarks.&lt;/p&gt;
&lt;h3 id="project-goals"&gt;Project Goals&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Create a hierarchical taxonomy of 3D pose estimation methods (single-view vs. multi-view, model-based vs. model-free, etc.)&lt;/li&gt;
&lt;li&gt;Provide performance comparisons on standard datasets (Human3.6M, MPI-INF-3DHP)&lt;/li&gt;
&lt;li&gt;Identify current challenges and promising future research directions&lt;/li&gt;
&lt;li&gt;Develop an interactive web-based tool for exploring the literature taxonomy&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="current-status"&gt;Current Status&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Literature Collection:&lt;/strong&gt; Complete (217 papers)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taxonomy Development:&lt;/strong&gt; Complete&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance Benchmarking:&lt;/strong&gt; In progress&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manuscript Draft:&lt;/strong&gt; In progress&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="expected-outcome"&gt;Expected Outcome&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Journal submission to &lt;em&gt;ACM Computing Surveys&lt;/em&gt; (CSUR)&lt;/li&gt;
&lt;li&gt;Release of an interactive online literature exploration platform&lt;/li&gt;
&lt;li&gt;Release of a standardized benchmarking codebase&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>From Pose to Semantic Segmentation</title><link>https://nancyaq.github.io/vml-website/projects/pose-estimation/pose-seg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nancyaq.github.io/vml-website/projects/pose-estimation/pose-seg/</guid><description>&lt;h3 id="overview"&gt;Overview&lt;/h3&gt;
&lt;p&gt;This sub-project tackles the challenging problem of segmenting humans in densely crowded scenes, where individuals often occlude each other. Traditional segmentation models struggle in these scenarios. We propose a novel multi-task framework that uses estimated human pose as a strong prior to guide the segmentation network, significantly improving performance in complex environments.&lt;/p&gt;
&lt;h3 id="key-innovations"&gt;Key Innovations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pose-Guided Attention Modules:&lt;/strong&gt; Architectural components that allow the segmentation network to focus on articulated body parts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthetic Crowd Generation:&lt;/strong&gt; A pipeline for creating realistic synthetic training data for crowded scenarios.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Occlusion-Robust Losses:&lt;/strong&gt; Novel loss functions designed to handle frequent occlusions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="datasets"&gt;Datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;COCO-Pose&lt;/li&gt;
&lt;li&gt;CrowdPose&lt;/li&gt;
&lt;li&gt;Our synthetic VML-Crowded dataset (to be released)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="publications"&gt;Publications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;D. Cohen, J. Smith, &amp;ldquo;Pose2Seg: Leveraging Keypoints for Human Instance Segmentation,&amp;rdquo; &lt;em&gt;IEEE Conference on Computer Vision and Pattern Recognition (CVPR)&lt;/em&gt;, 2024. (Submitted)&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>