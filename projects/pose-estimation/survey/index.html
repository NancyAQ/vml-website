<!doctype html><html lang=en><head><title>Comprehensive Survey of 3D Human Pose Estimation | VML-BGU</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><link rel=stylesheet href=/vml-website/style.css><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://nancyaq.github.io/vml-website/images/lab.jpg"><meta name=twitter:title content="Comprehensive Survey of 3D Human Pose Estimation"><meta name=twitter:description content="A systematic review and taxonomy of deep learning methods for 3D human pose estimation from monocular and multi-view images."><meta property="og:url" content="https://nancyaq.github.io/vml-website/projects/pose-estimation/survey/"><meta property="og:site_name" content="VML-BGU"><meta property="og:title" content="Comprehensive Survey of 3D Human Pose Estimation"><meta property="og:description" content="A systematic review and taxonomy of deep learning methods for 3D human pose estimation from monocular and multi-view images."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="og:image" content="https://nancyaq.github.io/vml-website/images/lab.jpg"></head><body class=is-preload><div id=page-wrapper><div id=header><div id=logo-wrapper><h1><a href=https://nancyaq.github.io/vml-website/ id=logo>VML-BGU</a></h1></div><nav id=nav><ul><li><a href=/vml-website/about>About</a><li><a href=/vml-website/team>Team</a><li><a href=/vml-website/projects/>Projects</a><li><a href=/vml-website/publications>Publications</a><li><a href=/vml-website/contact>Contact</a></ul></nav></div><section class="wrapper style1"><div class=container><div><div id=content><article><header><h2>Comprehensive Survey of 3D Human Pose Estimation</h2><p>A systematic review and taxonomy of deep learning methods for 3D human pose estimation from monocular and multi-view images.</p><ul class=tags></ul></header><h3 id=overview>Overview</h3><p>This project involves creating the most comprehensive survey to date on 3D Human Pose Estimation methods. We systematically categorize over 200 papers published in the last five years, creating a clear taxonomy of approaches, and providing quantitative comparisons of performance across standard benchmarks.</p><h3 id=project-goals>Project Goals</h3><ol><li>Create a hierarchical taxonomy of 3D pose estimation methods (single-view vs. multi-view, model-based vs. model-free, etc.)</li><li>Provide performance comparisons on standard datasets (Human3.6M, MPI-INF-3DHP)</li><li>Identify current challenges and promising future research directions</li><li>Develop an interactive web-based tool for exploring the literature taxonomy</li></ol><h3 id=current-status>Current Status</h3><ul><li><strong>Literature Collection:</strong> Complete (217 papers)</li><li><strong>Taxonomy Development:</strong> Complete</li><li><strong>Performance Benchmarking:</strong> In progress</li><li><strong>Manuscript Draft:</strong> In progress</li></ul><h3 id=expected-outcome>Expected Outcome</h3><ul><li>Journal submission to <em>ACM Computing Surveys</em> (CSUR)</li><li>Release of an interactive online literature exploration platform</li><li>Release of a standardized benchmarking codebase</li></ul></article></div></div></div></section><div id=footer><div class=container><div class=row><section class="col-12 col-6-narrower col-12-mobilep"><h3>important links</h3><ul class=links><li><a href="https://scholar.google.com.hk/citations?user=gG4J-vcAAAAJ&amp;hl=th">Google Scholar</a></ul></section></div></div><ul class=icons><li><a href=https://github.com/AI-Computer-Vision-BGU class="icon brands fa-github"><span class=label>GitHub</span></a></ul><div class=copyright><ul class=menu><li>Design: <a href=https://html5up.net>HTML5 UP</a><li><a href=https://github.com/half-duplex/hugo-arcana>Theme</a></ul></div></div></div><script src=/vml-website/js/jquery.min.js></script><script src=/vml-website/js/jquery.dropotron.min.js></script><script src=/vml-website/js/browser.min.js></script><script src=/vml-website/js/breakpoints.min.js></script><script src=/vml-website/js/util.js></script><script src=/vml-website/js/main.js></script></body></html>