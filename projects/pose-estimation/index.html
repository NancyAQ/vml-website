<!doctype html><html lang=en><head><title>Human Pose Estimation & Analysis | VML-BGU</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><link rel=stylesheet href=/vml-website/style.css><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://nancyaq.github.io/vml-website/images/lab.jpg"><meta name=twitter:title content="Human Pose Estimation & Analysis"><meta name=twitter:description content="Developing advanced computer vision models for 2D and 3D human pose estimation, with applications in healthcare, sports analytics, and human-computer interaction."><meta property="og:url" content="https://nancyaq.github.io/vml-website/projects/pose-estimation/"><meta property="og:site_name" content="VML-BGU"><meta property="og:title" content="Human Pose Estimation & Analysis"><meta property="og:description" content="Developing advanced computer vision models for 2D and 3D human pose estimation, with applications in healthcare, sports analytics, and human-computer interaction."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://nancyaq.github.io/vml-website/images/lab.jpg"></head><body class=is-preload><div id=page-wrapper><div id=header><div id=logo-wrapper><h1><a href=https://nancyaq.github.io/vml-website/ id=logo>VML-BGU</a></h1></div><nav id=nav><ul><li><a href=/vml-website/about>About</a><li><a href=/vml-website/team>Team</a><li><a href=/vml-website/projects/>Projects</a><li><a href=/vml-website/publications>Publications</a><li><a href=/vml-website/contact>Contact</a></ul></nav></div><section class="wrapper style1"><div class=container><div><div id=content><article><article class=post><header><h1>Human Pose Estimation & Analysis</h1></header><p>The Human Pose Estimation project at VML-BGU focuses on pushing the boundaries of how machines understand human body movement and articulation. We develop novel deep learning architectures that are more accurate, efficient, and robust to diverse real-world conditions such as occlusions, unusual clothing, and complex backgrounds.</p><p>Our research spans the entire pipeline from 2D keypoint detection to 3D pose reconstruction and temporal analysis for action recognition.</p><div class=projects-hierarchy></div></article><script>function toggleCollapse(e){e.classList.toggle("active");var t=e.nextElementSibling;t.style.display==="block"?(t.style.display="none",e.querySelector(".toggle-icon").textContent="▼"):(t.style.display="block",e.querySelector(".toggle-icon").textContent="▲")}</script></article></div></div></div></section><div id=footer><div class=container><div class=row><section class="col-12 col-6-narrower col-12-mobilep"><h3>important links</h3><ul class=links><li><a href="https://scholar.google.com.hk/citations?user=gG4J-vcAAAAJ&amp;hl=th">Google Scholar</a></ul></section></div></div><ul class=icons><li><a href=https://github.com/AI-Computer-Vision-BGU class="icon brands fa-github"><span class=label>GitHub</span></a></ul><div class=copyright><ul class=menu><li>Design: <a href=https://html5up.net>HTML5 UP</a><li><a href=https://github.com/half-duplex/hugo-arcana>Theme</a></ul></div></div></div><script src=/vml-website/js/jquery.min.js></script><script src=/vml-website/js/jquery.dropotron.min.js></script><script src=/vml-website/js/browser.min.js></script><script src=/vml-website/js/breakpoints.min.js></script><script src=/vml-website/js/util.js></script><script src=/vml-website/js/main.js></script></body></html>